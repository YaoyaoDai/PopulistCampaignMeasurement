{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaoyao/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.deprecated.doc2vec import LabeledSentence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import json\n",
    "\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "punctuation_dictionary = {s:None for s in list(string.punctuation)}\n",
    "punctuation_dictionary[\"-\"] = \"_\"\n",
    "punctuation_translator = str.maketrans(punctuation_dictionary)\n",
    "\n",
    "def text_cleaner(text, punctuation_translator, stemmer):\n",
    "    text = str(text).translate(punctuation_translator)\n",
    "    text = text.lower()\n",
    "    text = porter.stem(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Speech & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_index</th>\n",
       "      <th>SubContent</th>\n",
       "      <th>Subspeech_index</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Type</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speech0</td>\n",
       "      <td>['', \"PRESIDENT DONALD TRUMP: Thank you, thank...</td>\n",
       "      <td>Speech0_0:10</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>\\nRemarks at a \"Make America Great Again\" Rall...</td>\n",
       "      <td>\\nNovember 26, 2018</td>\n",
       "      <td>\\nPRESIDENT DONALD TRUMP: Thank you, thank you...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-make-america-great-again-ra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speech0</td>\n",
       "      <td>['The unemployment rate just hit the lowest le...</td>\n",
       "      <td>Speech0_10:20</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>\\nRemarks at a \"Make America Great Again\" Rall...</td>\n",
       "      <td>\\nNovember 26, 2018</td>\n",
       "      <td>\\nPRESIDENT DONALD TRUMP: Thank you, thank you...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-make-america-great-again-ra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speech0</td>\n",
       "      <td>[\"And I'll tell you, a little—a little tricky ...</td>\n",
       "      <td>Speech0_20:30</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>\\nRemarks at a \"Make America Great Again\" Rall...</td>\n",
       "      <td>\\nNovember 26, 2018</td>\n",
       "      <td>\\nPRESIDENT DONALD TRUMP: Thank you, thank you...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-make-america-great-again-ra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speech0</td>\n",
       "      <td>['You are here, he is here to help elect Cindy...</td>\n",
       "      <td>Speech0_30:40</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>\\nRemarks at a \"Make America Great Again\" Rall...</td>\n",
       "      <td>\\nNovember 26, 2018</td>\n",
       "      <td>\\nPRESIDENT DONALD TRUMP: Thank you, thank you...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-make-america-great-again-ra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Speech0</td>\n",
       "      <td>[\"What a great crowd we have tonight for you. ...</td>\n",
       "      <td>Speech0_40:50</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>\\nRemarks at a \"Make America Great Again\" Rall...</td>\n",
       "      <td>\\nNovember 26, 2018</td>\n",
       "      <td>\\nPRESIDENT DONALD TRUMP: Thank you, thank you...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-make-america-great-again-ra...</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Speech_index                                         SubContent  \\\n",
       "0           0      Speech0  ['', \"PRESIDENT DONALD TRUMP: Thank you, thank...   \n",
       "1           1      Speech0  ['The unemployment rate just hit the lowest le...   \n",
       "2           2      Speech0  [\"And I'll tell you, a little—a little tricky ...   \n",
       "3           3      Speech0  ['You are here, he is here to help elect Cindy...   \n",
       "4           4      Speech0  [\"What a great crowd we have tonight for you. ...   \n",
       "\n",
       "  Subspeech_index        Candidate  \\\n",
       "0    Speech0_0:10  Donald J. Trump   \n",
       "1   Speech0_10:20  Donald J. Trump   \n",
       "2   Speech0_20:30  Donald J. Trump   \n",
       "3   Speech0_30:40  Donald J. Trump   \n",
       "4   Speech0_40:50  Donald J. Trump   \n",
       "\n",
       "                                               Title                  Date  \\\n",
       "0  \\nRemarks at a \"Make America Great Again\" Rall...  \\nNovember 26, 2018    \n",
       "1  \\nRemarks at a \"Make America Great Again\" Rall...  \\nNovember 26, 2018    \n",
       "2  \\nRemarks at a \"Make America Great Again\" Rall...  \\nNovember 26, 2018    \n",
       "3  \\nRemarks at a \"Make America Great Again\" Rall...  \\nNovember 26, 2018    \n",
       "4  \\nRemarks at a \"Make America Great Again\" Rall...  \\nNovember 26, 2018    \n",
       "\n",
       "                                             Content                Type  \\\n",
       "0  \\nPRESIDENT DONALD TRUMP: Thank you, thank you...  Campaign Documents   \n",
       "1  \\nPRESIDENT DONALD TRUMP: Thank you, thank you...  Campaign Documents   \n",
       "2  \\nPRESIDENT DONALD TRUMP: Thank you, thank you...  Campaign Documents   \n",
       "3  \\nPRESIDENT DONALD TRUMP: Thank you, thank you...  Campaign Documents   \n",
       "4  \\nPRESIDENT DONALD TRUMP: Thank you, thank you...  Campaign Documents   \n",
       "\n",
       "                                                 URL  Year     Month  Day  Pop  \n",
       "0  /documents/remarks-make-america-great-again-ra...  2018  November   26  NaN  \n",
       "1  /documents/remarks-make-america-great-again-ra...  2018  November   26  NaN  \n",
       "2  /documents/remarks-make-america-great-again-ra...  2018  November   26  NaN  \n",
       "3  /documents/remarks-make-america-great-again-ra...  2018  November   26  NaN  \n",
       "4  /documents/remarks-make-america-great-again-ra...  2018  November   26  NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubSpeech = pd.read_csv('SubSpeech_coded.csv')\n",
    "SubSpeech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech[\"clean_text\"] = SubSpeech[\"SubContent\"].apply(lambda x: text_cleaner(x, punctuation_translator, porter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SubSpeech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases1 = Phrases(map(lambda x: x.split(), SubSpeech[\"clean_text\"].tolist()))\n",
    "phrases2 = Phrases(phrases1[map(lambda x: x.split(), SubSpeech[\"clean_text\"].tolist())])\n",
    "SubSpeech[\"phrased_text\"] = SubSpeech[\"clean_text\"].apply(lambda x: \" \".join(phrases2[phrases1[x.split()]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vev Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = list(zip(SubSpeech[\"phrased_text\"].tolist(), SubSpeech[\"Subspeech_index\"].tolist()))\n",
    "\n",
    "\n",
    "## Define an iterator to feed documents and tags to Doc2Vec\n",
    "class Sentences(object):\n",
    "  def __init__(self, docs):\n",
    "    self.docs = docs\n",
    "  def __iter__(self):\n",
    "    for doc in self.docs:\n",
    "      yield TaggedDocument(words=str(doc[0]).split(), tags=[doc[1]])\n",
    "\n",
    "## Train and save models\n",
    "model = Doc2Vec(Sentences(docs), vector_size=100, window=10, min_count=5, negative=10, epochs=20, dm=0, dbow_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"doc2vec_wordvecs.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('washington_dc', 0.668540358543396),\n",
       " ('game_playing', 0.6560088992118835),\n",
       " ('washington_insiders', 0.6413161754608154),\n",
       " ('influence_peddling', 0.6388410329818726),\n",
       " ('politics', 0.6355743408203125),\n",
       " ('politicians', 0.634049654006958),\n",
       " ('special_interests', 0.6225845813751221),\n",
       " ('change', 0.620872974395752),\n",
       " ('wont_do', 0.6165003776550293),\n",
       " ('lobbyists', 0.6142523288726807)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "['we will repeal and replace_disastrous_obamacare president_obama promised his plan would reduce premiums_by_2500 dollars instead they surged 5000 our replacement plan includes expanded access to healthcare savings_accounts with support for those_who need it it includes allowing americans to buy health_insurance across state lines in all 50_states creating a dynamic and competitive new market – they will be competing for your business were also going to block_grant medicaid so states can develop innovative_solutions to make_sure no citizen in poverty ever falls through the cracks high_risk pools will also help to ensure that those with_pre_existing_conditions will always get the quality coverage they need on trade we are going to end the international abuse the foreign_cheating and the one_sided rules that govern nafta and the world_trade_organization right_now america eliminates its tariffs but then other_countries tax our goods with backdoor tariffs and close their markets our massive chronic trade_deficits are destroying the middle_class – and shifting money away_from workers to large_corporations who have no borders theres a reason hedge_funds and wall_street are giving tens of millions to my_opponent hillary_clinton is the voice for the global_special_interests i_am_running to be the voice of the forgotten_men and women my_opponent likes to say that for decades she has_been fighting for women that she has_been fighting for children why then are 70_million american women and children living in poverty or on the brink of poverty why has she provided no relief for the millions of americans in search of affordable reliable quality_childcare you know the old saying watch what i do not what i sai']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('global_special_interests', 0.5951030850410461),\n",
       " ('allow_medicare', 0.5717523097991943),\n",
       " ('foreign_cheating', 0.55609130859375),\n",
       " ('empowering', 0.5533382892608643),\n",
       " ('instantly', 0.541082501411438),\n",
       " ('access', 0.527299165725708),\n",
       " ('lower_income', 0.5212934613227844),\n",
       " ('timely_access', 0.5169598460197449),\n",
       " ('their_prescription_drugs', 0.5145695805549622),\n",
       " ('healthcare', 0.5127156972885132)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most similar phrase to populist doc\n",
    "populist_index = list(set(SubSpeech.loc[SubSpeech['Pop'] == \"accept\", \"Subspeech_index\"].tolist()))\n",
    "print(len(populist_index))\n",
    "i = 3\n",
    "\n",
    "value = SubSpeech.loc[SubSpeech['Subspeech_index']==populist_index[i]][\"phrased_text\"].tolist()\n",
    "print(value)\n",
    "model.wv.most_similar([model.docvecs[populist_index[i]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech = pd.read_csv('SubSpeech_coded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2vec.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech.Pop.replace('accept',1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech.Pop.replace('reject',0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    226\n",
       "1.0     42\n",
       "Name: Pop, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubSpeech.Pop.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Pop\n",
      "Subspeech_index       \n",
      "Speech110_0:10     0.0\n",
      "Speech110_100:120  0.0\n",
      "Speech110_10:20    0.0\n",
      "Speech110_20:30    1.0\n",
      "Speech110_30:40    1.0\n",
      "(268, 1)\n",
      "(268, 100)\n",
      "[0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labelled_data = SubSpeech.loc[SubSpeech['Pop'].isin([0,1])][[\"Subspeech_index\",\"Pop\"]]\n",
    "labelled_data = labelled_data.groupby([\"Subspeech_index\"]).mean()\n",
    "print(labelled_data.head())\n",
    "print(labelled_data.shape)\n",
    "\n",
    "X = np.asarray([model.docvecs[i] for i in labelled_data.index.tolist()])\n",
    "Y = np.asarray(labelled_data['Pop'].tolist(), dtype=\"int\")\n",
    "\n",
    "# ## Get the words most closely associated with all of the \"populist\" articles\n",
    "# for k, v in model.most_similar(model.docvecs[populist_indices], topn=50):\n",
    "#   print(k) \n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "print(X.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.899540757749713\n",
      "Accuracy: 0.8375\n",
      "Mean AUC: 0.899540757749713\n",
      "Mean Accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "auc_scores_d2v = []\n",
    "accuracy_scores_d2v = []\n",
    "\n",
    "np.random.seed(1234) \n",
    "random.seed(1234)\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['xtick.color'] = 'black'\n",
    "plt.rcParams['ytick.color'] = 'black'\n",
    "plt.rcParams['axes.labelcolor'] = 'black'\n",
    "plt.rcParams['savefig.transparent'] = 'false'\n",
    "\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "#plt.title('ROC curve', fontsize=16)\n",
    "for i in range(1):\n",
    "    ## Create a test and train set\n",
    "    test_size = 80\n",
    "    test_set = random.sample(range(0,len(Y)), test_size)\n",
    "    train_set = list(set(list(range(0,len(Y)))) - set(test_set))\n",
    "    ## Initialize a gradient boosting classifier\n",
    "    gbc = RandomForestClassifier(n_estimators=5000, max_depth=10, random_state=0, class_weight=\"balanced\")\n",
    "  # gbc = GradientBoostingClassifier(loss=\"deviance\",\n",
    "  #   learning_rate=0.1,\n",
    "  #   n_estimators=20000,\n",
    "  #   subsample=1.0,\n",
    "  #   min_samples_split=2,\n",
    "  #   min_samples_leaf=1,\n",
    "  #   max_depth=4,\n",
    "  #   init=None,\n",
    "  #   random_state=None,\n",
    "  #   max_features=None,\n",
    "  #   verbose=0)\n",
    "    gbc = CalibratedClassifierCV(gbc, cv=2, method=\"isotonic\")\n",
    "    ## Fit the model to the training set\n",
    "    gbc.fit(X[np.asarray(train_set, dtype=\"int\")], Y[np.asarray(train_set, dtype=\"int\")])\n",
    "    ## Predict out-of-sample on the test set and compute AUC\n",
    "    preds = gbc.predict_proba(X[np.asarray(test_set, dtype=\"int\")])\n",
    "    fpr_d2v, tpr_d2v, thresholds_d2v = metrics.roc_curve(Y[np.asarray(test_set, dtype=\"int\")], preds[:,1], pos_label=1)\n",
    "    auc_scores_d2v = auc_scores_d2v + [metrics.auc(fpr_d2v, tpr_d2v)]\n",
    "    plt.plot(fpr_d2v, tpr_d2v, lw=2, linestyle='--', label=\"AUC:\" + str(metrics.auc(fpr_d2v, tpr_d2v))[0:4],color='#fd8d3c')\n",
    "    print(\"AUC: \"+str(metrics.auc(fpr_d2v, tpr_d2v)))\n",
    "    accuracy_d2v = metrics.accuracy_score(Y[np.asarray(test_set, dtype=\"int\")], gbc.predict(X[np.asarray(test_set, dtype=\"int\")]), normalize=True)\n",
    "    accuracy_scores_d2v = accuracy_scores_d2v + [accuracy_d2v]\n",
    "    print(\"Accuracy: \" + str(accuracy_d2v))\n",
    "leg = plt.legend(framealpha = 0,loc='lower right', fontsize=13)\n",
    "for text in leg.get_texts():\n",
    "    plt.setp(text, color = 'black')\n",
    "plt.savefig('images/d2v_rocs.png')\n",
    "# vocab = model.wv.vocab.keys()\n",
    "# vectors = [model[v] for v in vocab]\n",
    "# vectors = np.asarray(vectors)\n",
    "\n",
    "# word_preds = gbc.predict_proba(vectors)\n",
    "# word_scores = dict(zip(vocab, word_preds[:,1].tolist()))\n",
    "# sorted_keys = sorted(word_scores, key=word_scores.get, reverse=True)\n",
    "# for r in sorted_keys[0:100]:\n",
    "#     print(str(r))\n",
    "print(\"Mean AUC: \" + str(np.mean(auc_scores_d2v)))\n",
    "print(\"Mean Accuracy: \" + str(np.mean(accuracy_scores_d2v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  0]\n",
      " [13  0]]\n"
     ]
    }
   ],
   "source": [
    "predicted = gbc.predict(X[np.asarray(test_set, dtype=\"int\")])\n",
    "confusion = confusion_matrix(Y[np.asarray(test_set, dtype=\"int\")], predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = unique_labels(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[67  0]\n",
      " [13  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ec65f28>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(Y[np.asarray(test_set, dtype=\"int\")], predicted, \n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = gbc.predict_proba(np.asarray([model.docvecs[a] for a in SubSpeech[\"Subspeech_index\"]]))\n",
    "predictions = gbc.predict(np.asarray([model.docvecs[a] for a in SubSpeech[\"Subspeech_index\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech[\"Pop_class\"] = predictions.tolist()\n",
    "SubSpeech[\"Pop_prob\"] = scores[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11929.000000\n",
       "mean         0.109605\n",
       "std          0.078837\n",
       "min          0.047170\n",
       "25%          0.047170\n",
       "50%          0.092624\n",
       "75%          0.147170\n",
       "max          0.458333\n",
       "Name: Pop_prob, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubSpeech[\"Pop_prob\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SubSpeech.sort_values(by=['Pop_prob']).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech[\"Pop_class\"] = [1 if x>=0.4 else 0 for x in SubSpeech[\"Pop_prob\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02288540531477911"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(SubSpeech[\"Pop_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[220   6]\n",
      " [ 20  22]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1217bdef0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_confusion_matrix(SubSpeech.loc[SubSpeech['Pop'].isin([0,1])][\"Pop\"], \n",
    "                      SubSpeech.loc[SubSpeech['Pop'].isin([0,1])][\"Pop_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech.to_csv('SubSpeech_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blind Test (prodigy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech_predicted = pd.read_csv('SubSpeech_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SubSpeech_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "virgintext = SubSpeech.loc[-SubSpeech['Pop'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "virgintext = virgintext[virgintext.Candidate != 'Donald J. Trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Barack Obama             12\n",
       "Bernie Sanders            9\n",
       "John Edwards              5\n",
       "Robert Dole               5\n",
       "Hillary Clinton           5\n",
       "Ted Cruz                  3\n",
       "Rick Perry                3\n",
       "Mitt Romney               3\n",
       "John F. Kerry             3\n",
       "Bill Richardson           2\n",
       "John McCain               2\n",
       "Scott Walker              2\n",
       "Mike Pence                1\n",
       "Newt Gingrich             1\n",
       "Albert Gore, Jr.          1\n",
       "Franklin D. Roosevelt     1\n",
       "John F. Kennedy           1\n",
       "Mike Huckabee             1\n",
       "Fred Thompson             1\n",
       "Rudy Giuliani             1\n",
       "Jon Huntsman              1\n",
       "Name: Candidate, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virgintext[virgintext.Pop_class==1].Candidate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#virgintext.Subspeech_index[virgintext.Pop_class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blind_index = list(np.random.choice(virgintext.Subspeech_index[virgintext.Pop_class==1], 10, replace=False)) + list(\n",
    "    np.random.choice(virgintext.Subspeech_index[virgintext.Pop_class==0], 5, replace=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindspeech_index = [re.split('_',x)[0] for x in blind_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindspeech_sample = SubSpeech[['Speech_index', 'Subspeech_index','SubContent']].loc[\n",
    "    SubSpeech.Speech_index.isin(blindspeech_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindspeech_sample['text'] = [blindspeech_sample.Subspeech_index[i] + '## ' + ''.join(blindspeech_sample.SubContent[i])\n",
    "                           for i in blindspeech_sample.Subspeech_index.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blindspeech_sample.Subspeech_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindspeech_sample.to_csv('blindspeech_sample2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindspeech_sample = pd.read_csv(\"blindspeech_sample2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008    50\n",
       "1996    24\n",
       "2011    12\n",
       "2015    10\n",
       "2016     9\n",
       "2007     6\n",
       "2004     6\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubSpeech.loc[\n",
    "    SubSpeech.Speech_index.isin(blindspeech_index)].Year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SubSpeech_predicted.Candidate[SubSpeech_predicted.Speech_index.isin(blindspeech_sample.Speech_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SubSpeech.Speech_index.loc[SubSpeech['Pop'].isin([0,1])].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speech_index</th>\n",
       "      <th>SubContent</th>\n",
       "      <th>Subspeech_index</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Type</th>\n",
       "      <th>URL</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Pop_class</th>\n",
       "      <th>Pop_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>9480</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['', 'A few weeks ago, President Clinton looke...</td>\n",
       "      <td>Speech1754_0:10</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>9481</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['A mother of two who is worried her job may b...</td>\n",
       "      <td>Speech1754_10:20</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>9482</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['Let me briefly touch upon each of these four...</td>\n",
       "      <td>Speech1754_20:30</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>9483</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['If you go to any Main Street in America, and...</td>\n",
       "      <td>Speech1754_30:40</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.438596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>9484</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['In designing a new tax system I will ensure ...</td>\n",
       "      <td>Speech1754_40:50</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>Speech1754</td>\n",
       "      <td>['As President, I would direct every Departmen...</td>\n",
       "      <td>Speech1754_50:70</td>\n",
       "      <td>Robert Dole</td>\n",
       "      <td>\\nRemarks at Hudson Chamber of Commerce\\n</td>\n",
       "      <td>\\nFebruary 22, 1996</td>\n",
       "      <td>\\nA few weeks ago, President Clinton looked Am...</td>\n",
       "      <td>Campaign Documents</td>\n",
       "      <td>/documents/remarks-hudson-chamber-commerce</td>\n",
       "      <td>1996</td>\n",
       "      <td>February</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Speech_index  \\\n",
       "9480        9480   Speech1754   \n",
       "9481        9481   Speech1754   \n",
       "9482        9482   Speech1754   \n",
       "9483        9483   Speech1754   \n",
       "9484        9484   Speech1754   \n",
       "9485        9485   Speech1754   \n",
       "\n",
       "                                             SubContent   Subspeech_index  \\\n",
       "9480  ['', 'A few weeks ago, President Clinton looke...   Speech1754_0:10   \n",
       "9481  ['A mother of two who is worried her job may b...  Speech1754_10:20   \n",
       "9482  ['Let me briefly touch upon each of these four...  Speech1754_20:30   \n",
       "9483  ['If you go to any Main Street in America, and...  Speech1754_30:40   \n",
       "9484  ['In designing a new tax system I will ensure ...  Speech1754_40:50   \n",
       "9485  ['As President, I would direct every Departmen...  Speech1754_50:70   \n",
       "\n",
       "        Candidate                                      Title  \\\n",
       "9480  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "9481  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "9482  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "9483  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "9484  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "9485  Robert Dole  \\nRemarks at Hudson Chamber of Commerce\\n   \n",
       "\n",
       "                      Date                                            Content  \\\n",
       "9480  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "9481  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "9482  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "9483  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "9484  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "9485  \\nFebruary 22, 1996   \\nA few weeks ago, President Clinton looked Am...   \n",
       "\n",
       "                    Type                                         URL  Year  \\\n",
       "9480  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "9481  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "9482  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "9483  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "9484  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "9485  Campaign Documents  /documents/remarks-hudson-chamber-commerce  1996   \n",
       "\n",
       "         Month  Day  Pop  Pop_class  Pop_prob  \n",
       "9480  February   22  NaN          0  0.047170  \n",
       "9481  February   22  NaN          0  0.147170  \n",
       "9482  February   22  NaN          0  0.083333  \n",
       "9483  February   22  NaN          1  0.438596  \n",
       "9484  February   22  NaN          0  0.158550  \n",
       "9485  February   22  NaN          0  0.128788  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubSpeech_predicted.loc[SubSpeech_predicted.Speech_index == \"Speech1754\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merge Blind Test Annotation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Annotations/blind_test1117.jsonl', 'r') as annotation_jsonl:\n",
    "    annotation_list = list(annotation_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded = {}\n",
    "for annotation in annotation_list:\n",
    "    annotation_dict = json.loads(annotation)\n",
    "    coded[annotation_dict['text'].split('##')[0]] = annotation_dict['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blindtest_coded = pd.DataFrame.from_dict(coded, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindtest_coded = blindtest_coded.rename(columns={0:'Pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindtest_coded['Subspeech_index'] = blindtest_coded.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech = pd.read_csv('SubSpeech_coded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blindtest = SubSpeech.merge(blindtest_coded, how = 'outer', left_on='Subspeech_index', right_on = 'Subspeech_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blindtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update training data with all annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Annotations/test_annotation.jsonl', 'r') as annotation_jsonl:\n",
    "    annotation_list += list(annotation_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Annotations/pop_code1117.jsonl', 'r') as annotation_jsonl:\n",
    "    annotation_list += list(annotation_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coded = {}\n",
    "for annotation in annotation_list:\n",
    "    annotation_dict = json.loads(annotation)\n",
    "    coded[annotation_dict['text'].split('##')[0]] = annotation_dict['answer']\n",
    "\n",
    "coded_data = pd.DataFrame.from_dict(coded, orient='index')\n",
    "coded_data = coded_data.rename(columns={0:'Pop'})\n",
    "coded_data['Subspeech_index'] = coded_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coded_data.Pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sub_Speech = pd.read_csv('SubSpeech.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech_coded = Sub_Speech.merge(coded_data, how = 'outer', left_on='Subspeech_index', right_on = 'Subspeech_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SubSpeech_coded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SubSpeech_coded.to_csv(\"SubSpeech_coded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
